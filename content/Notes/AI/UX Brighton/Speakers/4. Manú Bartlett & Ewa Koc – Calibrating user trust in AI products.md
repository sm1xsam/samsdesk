
## Key Insights

### 1. User Confidence and Trust
- **Human-AI Relationship**: The level of trust users have in AI is closely tied to their confidence in their own knowledge of the field.
- **Background**: Derived from *Humans and Automation* (1997).
- **Trust and System Reliability**: Users' trust in an AI system aligns with its actual capability, reliability, and the associated risks. In short, users trust it more if it proves reliable.

### 2. Building Trust in AI
- **Explainability**: Providing user-friendly explanations of how AI works builds trust. Any explanation is generally better than none.
- **Decision Transparency**: Clearly show why AI makes certain decisions, for example, by highlighting sources or showing key factors in the decision-making process.
- **Human-Friendly Design**:
  - Use empathetic language and positive reinforcement (including humour) where appropriate.
  - Incorporate human feedback loops and interaction points to make the experience feel more human.
- **Human-in-the-Loop Feedback**: Allow users to give feedback, keeping them engaged in the AI’s processes and outcomes.

### 3. Teaching Effective Use
- **Interactive Learning**: Design interactions that guide users on how to use AI effectively.
- **Immediate Feedback**: Users learn faster when they see a response to their actions right away.
- **Reliable Error Messages**: Clear and consistent error messages reduce user frustration and help build trust in the AI’s reliability.