## Reflections on the Talk

- Pablo Stanley was all over the place – I get that some people like this style but it left me feeling like I learned nothing 
- Chatbots don't need to be the default for AI – prompts that are connected to other interface elements like buttons 
	- whats the value in adding personality then? if its ai in the background instead of some other algorithm, why do we need to humanise it in a way we wouldn't have before - does this principle only apply to chatbots? 
- i think pablo's pushing for "prompts as buttons" to go side by side with an open-ended text box. i'd argue this approach could hinder user comfort and we need to push for the removal of the text input in places where it can be. 
 
## His points

### 1. Guiding Users to Interact Effectively with AI
- **Educational Guides**: Provide guides to teach users how to interact with AI efficiently and make the most out of its capabilities.

### 2. Ensuring Accurate User Input
- **Input Customisation**: Allow users to customise how the AI interprets their actions to improve accuracy and responsiveness.

### 3. Building Trust through Clarity
- **Capabilities and Limitations**: Clearly communicate what the AI can and cannot do to set realistic user expectations.
- **Transparency**: Be upfront about how the AI operates and any data usage. Stanley criticised Figma’s approach to consent, which requires users to uncheck settings to avoid data use for training, considering it a poor example of transparency.

### 4. Adding Personality to AI
- **Engagement**: Infuse a layer of personality into AI interactions to make them more memorable and enjoyable for users.

### 5. Separate Prompts and Actions
- **Description Buttons**: Consider having buttons dedicated to specific AI prompts, allowing users to control the AI's actions more directly and deliberately.